{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "Cross Validation & Naive Bayes Lab - SMS Spam Classification\n",
    "===============\n",
    "* orignally developed by Ankit Jain\n",
    "* modified by Justin Breucop\n",
    "* modified by Dylan Hercher\n",
    "\n",
    "Data source: https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation from Scratch\n",
    "\n",
    "Let's build it the function together! The steps to cross validation are:\n",
    "1. Randomly separate your training set into _k_ groups\n",
    "2. For each group _k_:\n",
    ">1. Train your model on the other groups\n",
    ">2. Score your model using group _k_ as validation\n",
    ">3. Save your score and move to your next group\n",
    "\n",
    "3. Add your _k_ scores and divide by _k_ to get your average score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Importing Packages \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier(10)\n",
    "\n",
    "df = pd.DataFrame.from_csv('../data/titanic-train.csv',index_col=None)[['Age','Pclass','SibSp','Survived']].dropna()\n",
    "to_predict = \"Survived\"\n",
    "features=['Age','Pclass','SibSp']\n",
    "data = df[features]\n",
    "label = df[to_predict]\n",
    "folds=5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build in class!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function here:\n",
    "def cross_validate_df(data,label,model,k):\n",
    "    x=len(df)\n",
    "    for i in range(0,k-1):\n",
    "        i1=i*x/k\n",
    "        i2=(i+1)*x/k-1\n",
    "        y_train=df[]\n",
    "        myknn = KNeighborsClassifier(3).fit(X_train,y_train)\n",
    "    \"\"\"Return Average score across k iterations\n",
    "    Parameters\n",
    "    -----------\n",
    "    data : DataFrame with features to use in X\n",
    "    label : Series with target y\n",
    "    model : ML Model to use\n",
    "    k : int number of iterations\n",
    "    \"\"\"\n",
    "    # TODO: Design the cross validation function\n",
    "    # it may be helpful to try writing the function with k=1 first\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Once Complete test your function here\n",
    "cross_validate_df(data,label,model,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Built-in Cross Validation\n",
    "There is also a very simple cross validation function provided by sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "# Results of using the built-in cross validation\n",
    "# Note: Default is Kfold, but within sklearn.cross_validation\n",
    "# there are many types of validation that can be used\n",
    "cross_val_score(model, data, label, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cross_val_score(model, data, label, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(cross_val_score(model, data, label, cv=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2)\n",
    "## Naive Bayes and SMS Spam Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## READING IN THE DATA\n",
    "df = pd.DataFrame.from_csv(\"../data/SMSSpamCollection.tsv\",sep='\\t',header=0,index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>msg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                                msg\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>msg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spam</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spam</td>\n",
       "      <td>WINNER!! As a valued network customer you have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>spam</td>\n",
       "      <td>SIX chances to win CASH! From 100 to 20,000 po...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                                msg\n",
       "2   spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "5   spam  FreeMsg Hey there darling it's been 3 week's n...\n",
       "8   spam  WINNER!! As a valued network customer you have...\n",
       "9   spam  Had your mobile 11 months or more? U R entitle...\n",
       "11  spam  SIX chances to win CASH! From 100 to 20,000 po..."
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.label=='spam'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     4825\n",
       "spam     747\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count                       5572\n",
       "unique                      5169\n",
       "top       Sorry, I'll call later\n",
       "freq                          30\n",
       "Name: msg, dtype: object"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.msg.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert the label into a binary variable\n",
    "# Remember the map function we learned before?\n",
    "df['label'] = df.label.map({'ham': 0 , 'spam':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>msg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                                msg\n",
       "0      0  Go until jurong point, crazy.. Available only ...\n",
       "1      0                      Ok lar... Joking wif u oni...\n",
       "2      1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      0  U dun say so early hor... U c already then say...\n",
       "4      0  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# split into training and testing sets by calling sklearn lib\n",
    "# by default, the data set is split into 0.75 (training) and 0.25 (testing)\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.msg, df.label, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4179,)\n",
      "710     4mths half price Orange line rental & latest c...\n",
      "3740                           Did you stitch his trouser\n",
      "2711    Hope you enjoyed your new content. text stop t...\n",
      "3155    Not heard from U4 a while. Call 4 rude chat pr...\n",
      "3748    Ãœ neva tell me how i noe... I'm not at home in...\n",
      "2389    wiskey Brandy Rum Gin Beer Vodka Scotch Shampa...\n",
      "3464    i am seeking a lady in the street and a freak ...\n",
      "772     Lol! U drunkard! Just doing my hair at d momen...\n",
      "3667    I'm turning off my phone. My moms telling ever...\n",
      "4955    U coming back 4 dinner rite? Dad ask me so i r...\n",
      "854     AH POOR BABY!HOPE URFEELING BETTERSN LUV! PROB...\n",
      "4079                  Gam gone after outstanding innings.\n",
      "2837                         Nice.nice.how is it working?\n",
      "1392                  Haha just kidding, papa needs drugs\n",
      "5533    Hey chief, can you give me a bell when you get...\n",
      "874     Ugh its been a long day. I'm exhausted. Just w...\n",
      "4408    Awesome, plan to get here any time after like ...\n",
      "3990    Ok lor. Anyway i thk we cant get tickets now c...\n",
      "1921                        Dont know you bring some food\n",
      "749     Is there a reason we've not spoken this year? ...\n",
      "2947                        make that 3! 4 fucks sake?! x\n",
      "2378    YES! The only place in town to meet exciting a...\n",
      "83                   You will be in the place of that man\n",
      "4668                           I send the print  outs da.\n",
      "128                                Are you there in room.\n",
      "4521    What to think no one saying clearly. Ok leave ...\n",
      "5090                             St andre, virgil's cream\n",
      "885     Yoyyooo u know how to change permissions for a...\n",
      "134     Sunshine Quiz Wkly Q! Win a top Sony DVD playe...\n",
      "3060    Dear all, as we know  &lt;#&gt; th is the  &lt...\n",
      "                              ...                        \n",
      "1031    Can not use foreign stamps in this country. Go...\n",
      "1110                      S s..first time..dhoni rocks...\n",
      "1888    Urgent! Please call 09061743811 from landline....\n",
      "3550    I got like $ &lt;#&gt; , I can get some more l...\n",
      "1527    Wow ... I love you sooo much, you know ? I can...\n",
      "753                           Dont gimme that lip caveboy\n",
      "3049             Die... Now i have e toot fringe again...\n",
      "2628    I know I'm lacking on most of this particular ...\n",
      "562                      Thanx 4 e brownie it's v nice...\n",
      "4764                           Prepare to be pleasured :)\n",
      "3562    Text BANNEDUK to 89555 to see! cost 150p texto...\n",
      "252     Wen ur lovable bcums angry wid u, dnt take it ...\n",
      "2516    Bognor it is! Should be splendid at this time ...\n",
      "2962    I'm doing da intro covers energy trends n pros...\n",
      "4453    I've told you everything will stop. Just dont ...\n",
      "5374    Do u konw waht is rael FRIENDSHIP Im gving yuo...\n",
      "5396             As in i want custom officer discount oh.\n",
      "1202                                 I know she called me\n",
      "3462    K.. I yan jiu liao... Sat we can go 4 bugis vi...\n",
      "2797    Tell your friends what you plan to do on Valen...\n",
      "4225    Double eviction this week - Spiral and Michael...\n",
      "144            I know you are. Can you pls open the back?\n",
      "5056    Am on a train back from northampton so i'm afr...\n",
      "2895                     K...k...yesterday i was in cbe .\n",
      "2763    ARR birthday today:) i wish him to get more os...\n",
      "905     We're all getting worried over here, derek and...\n",
      "5192    Oh oh... Den muz change plan liao... Go back h...\n",
      "3980    CERI U REBEL! SWEET DREAMZ ME LITTLE BUDDY!! C...\n",
      "235     Text & meet someone sexy today. U can find a d...\n",
      "5157                              K k:) sms chat with me.\n",
      "Name: msg, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print X_train.shape\n",
    "print X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1393,)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to convert the text into feature vectors which can be used for machine learning purposes.\n",
    "We will use the scikit function of CountVectorizer to 'convert text into a matrix of token counts'\n",
    "\n",
    " http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets try a simple example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# start with a simple example\n",
    "train_simple = ['call you tonight',\n",
    "                'Call me a cab',\n",
    "                'please call me... PLEASE!']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# learn the 'vocabulary' of the training data\n",
    "vect = CountVectorizer(decode_error='ignore')\n",
    "vect.fit(train_simple)\n",
    "vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# transform training data into a 'document-term matrix'\n",
    "train_simple_dtm = vect.transform(train_simple)\n",
    "train_simple_dtm.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We can see how we've adjusted our data easily!\n",
    "# examine the vocabulary and document-term matrix together\n",
    "print train_simple\n",
    "    \n",
    "pd.DataFrame(train_simple_dtm.toarray(), columns=vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# transform testing data into a document-term matrix (using existing vocabulary)\n",
    "test_simple = [\"please don't call me\"]\n",
    "test_simple_dtm = vect.transform(test_simple)\n",
    "test_simple_dtm.toarray()\n",
    "\n",
    "pd.DataFrame(test_simple_dtm.toarray(), columns=vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question:  How does the above test_simple show how things can go wrong?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise: Using the dataset below\n",
    "   * Vectorize the text\n",
    "   * Store the results in a DataFrame\n",
    "   * Show word counts (hint: one dataframe describer can do this)\n",
    "   * Transform the test text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_exp = ['where is my taco?',\n",
    "                'did I eat the taco',\n",
    "                'I can easily eat my way through that whole box of tacos!',\n",
    "                'I think way too much about tacos, huh',\n",
    "                'taco, taco, taco!!!'                \n",
    "               ]\n",
    "test_exp = [\n",
    "    'where did he go?', 'how long did the whole thing last', 'lets go eat one taco or multiple tacos'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# learn the 'vocabulary' of the training data\n",
    "vect = CountVectorizer(decode_error='ignore')\n",
    "vect.fit(train_exp)\n",
    "vect.get_feature_names()\n",
    "train_simple_dtm = vect.transform(train_exp)\n",
    "train_simple_dtm.toarray()\n",
    "test=vect.transform(test_exp)\n",
    "test.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizing our SMS Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'about',\n",
       " u'box',\n",
       " u'can',\n",
       " u'did',\n",
       " u'easily',\n",
       " u'eat',\n",
       " u'huh',\n",
       " u'is',\n",
       " u'much',\n",
       " u'my',\n",
       " u'of',\n",
       " u'taco',\n",
       " u'tacos',\n",
       " u'that',\n",
       " u'the',\n",
       " u'think',\n",
       " u'through',\n",
       " u'too',\n",
       " u'way',\n",
       " u'where',\n",
       " u'whole']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate the vectorizer ( use variable name as vect)\n",
    "vect = CountVectorizer(decode_error = 'ignore')\n",
    "vect.fit(train_exp)\n",
    "vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 14)\t1\n",
      "  (10, 9)\t1\n",
      "  (11, 9)\t1\n",
      "  (13, 7)\t1\n",
      "  (13, 10)\t1\n",
      "  (13, 14)\t1\n",
      "  (14, 2)\t1\n",
      "  (14, 9)\t1\n",
      "  (16, 9)\t1\n",
      "  (17, 14)\t1\n",
      "  (17, 18)\t1\n",
      "  (19, 13)\t1\n",
      "  (20, 2)\t1\n",
      "  (20, 9)\t1\n",
      "  (21, 2)\t1\n",
      "  (21, 7)\t1\n",
      "  (22, 0)\t1\n",
      "  (22, 14)\t1\n",
      "  (23, 13)\t1\n",
      "  (25, 7)\t1\n",
      "  (26, 19)\t1\n",
      "  (28, 7)\t3\n",
      "  (28, 14)\t1\n",
      "  (29, 2)\t1\n",
      "  (29, 7)\t1\n",
      "  :\t:\n",
      "  (1357, 0)\t1\n",
      "  (1361, 7)\t1\n",
      "  (1361, 9)\t1\n",
      "  (1361, 10)\t1\n",
      "  (1366, 9)\t1\n",
      "  (1367, 2)\t1\n",
      "  (1371, 7)\t1\n",
      "  (1373, 3)\t1\n",
      "  (1373, 15)\t1\n",
      "  (1373, 17)\t1\n",
      "  (1374, 7)\t1\n",
      "  (1374, 9)\t1\n",
      "  (1374, 13)\t1\n",
      "  (1374, 18)\t1\n",
      "  (1375, 10)\t1\n",
      "  (1377, 7)\t1\n",
      "  (1377, 14)\t1\n",
      "  (1378, 2)\t1\n",
      "  (1378, 7)\t1\n",
      "  (1378, 14)\t1\n",
      "  (1383, 7)\t1\n",
      "  (1383, 14)\t2\n",
      "  (1385, 7)\t1\n",
      "  (1385, 9)\t1\n",
      "  (1390, 7)\t1\n"
     ]
    }
   ],
   "source": [
    "# transform testing data into a document-term matrix: Use Variable name as test_dtm\n",
    "train_dtm = vect.transform(X_train)\n",
    "test_dtm = vect.transform(X_test)\n",
    "print test_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the length and names of the feature names\n",
    "train_features = vect.get_feature_names()\n",
    "len(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'about',\n",
       " u'box',\n",
       " u'can',\n",
       " u'did',\n",
       " u'easily',\n",
       " u'eat',\n",
       " u'huh',\n",
       " u'is',\n",
       " u'much',\n",
       " u'my',\n",
       " u'of',\n",
       " u'taco',\n",
       " u'tacos',\n",
       " u'that',\n",
       " u'the',\n",
       " u'think',\n",
       " u'through',\n",
       " u'too',\n",
       " u'way',\n",
       " u'where',\n",
       " u'whole']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'about',\n",
       " u'box',\n",
       " u'can',\n",
       " u'did',\n",
       " u'easily',\n",
       " u'eat',\n",
       " u'huh',\n",
       " u'is',\n",
       " u'much',\n",
       " u'my',\n",
       " u'of',\n",
       " u'taco',\n",
       " u'tacos',\n",
       " u'that',\n",
       " u'the',\n",
       " u'think',\n",
       " u'through',\n",
       " u'too',\n",
       " u'way',\n",
       " u'where',\n",
       " u'whole']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features[-50:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ..., \n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 1, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert train_dtm to a regular array\n",
    "train_arr = train_dtm.toarray()\n",
    "train_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "8\n",
      "[1 2 3 4]\n",
      "[1 5]\n",
      "36\n",
      "[ 6  8 10 12]\n",
      "[10 26]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Revisit Numpy\n",
    "arr = np.array([[1, 2, 3, 4], [5, 6, 7, 8]])\n",
    "print arr[0, 0]\n",
    "print arr[1, 3]\n",
    "print arr[0, :]\n",
    "print arr[:, 0]\n",
    "print np.sum(arr)\n",
    "print np.sum(arr,axis = 0)\n",
    "print np.sum(arr,axis = 1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# exercise: calculate the number of tokens in the 0th message in train_arr\n",
    "print np.sum(train_arr[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# exercise: count how many times the 0th token appears across ALL messages in train_arr\n",
    "print np.sum(train_arr[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# exercise: count how many times EACH token appears across ALL messages in train_arr\n",
    "print np.sum(train_arr, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# exercise: create a DataFrame of tokens with their counts.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's build the model with Naive Bayes Now\n",
    "\n",
    "http://scikit-learn.org/stable/modules/naive_bayes.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train a Naive Bayes model using train_dtm\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "nb = MultinomialNB()\n",
    "nb.fit(train_dtm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# make predictions on test data using test_dtm\n",
    "preds = nb.predict(test_dtm)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# compare predictions to true labels\n",
    "from sklearn import metrics\n",
    "print metrics.accuracy_score(y_test, preds)\n",
    "print metrics.confusion_matrix(y_test, preds)\n",
    "\n",
    "# confusion matrix: http://en.wikipedia.org/wiki/Confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# exercise: show the message text for the false positives\n",
    "X_test[(y_test == 0) & (preds == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# exercise: show the message text for the false negatives\n",
    "X_test[y_test > preds]\n",
    "# or\n",
    "X_test[(y_test == 1) & (preds == 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## USING ALL DATA AND CROSS-VALIDATION, run NB again\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Here is the condensed code needed for reference\n",
    "df = pd.DataFrame.from_csv(\"../data/SMSSpamCollection.tsv\",sep='\\t',header=0,index_col=None)\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.msg, df.label, random_state=1)\n",
    "df.label=df.label.map({'ham':00,'spam':1})\n",
    "vect = CountVectorizer(decode_error = 'ignore')\n",
    "\n",
    "vect.fit(X_train)\n",
    "vect.get_feature_names()\n",
    "\n",
    "train_dtm = vect.transform(X_train)\n",
    "test_dtm = vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7456"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vect.get_feature_names())\n",
    "## EXERCISE: CALCULATE THE 'SPAMMINESS' OF EACH TOKEN\n",
    "\n",
    "# create separate DataFrames for ham and spam ( df_ham and df_spam)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# learn the vocabulary of ALL messages and save it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create document-term matrix of ham, then convert to a regular array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create document-term matrix of spam, then convert to a regular array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# count how many times EACH token appears across ALL messages in ham_arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# count how many times EACH token appears across ALL messages in spam_arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a DataFrame of tokens with their separate ham and spam counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# add one to ham counts and spam counts so that ratio calculations (below) make more sensse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# calculate ratio of spam-to-ham for each token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# advanced: implement your own naive bayes classifier\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
