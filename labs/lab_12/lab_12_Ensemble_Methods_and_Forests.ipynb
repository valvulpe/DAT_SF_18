{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DAT18 Lab 12\n",
    "## Ensemble Methods: Aggregating Models\n",
    "\n",
    "\n",
    "Today's lab covers:\n",
    "1. Investigating the Decision Boundaries\n",
    "2. Growing a Random Forest\n",
    "\n",
    "The theory used to introduce these concepts can be a bit high level. We postulate a theoretical *true* classification **f** function that perfectly labels a data point given a large enough set of input features. We try to come as close as possible to this **f** with our learned classifier **h**. \n",
    "\n",
    "The concept of our *hypothesis space* is what we explore when we take our data, learn a model, and determine the \"score\" of our model. In theory, a cross validated score of 100 is as close as we can get to **f** and all these improvements we make to our classifiers are moving through the hypothesis space, approaching **f**.\n",
    "\n",
    "This theoretical component has no true lab but in a sense is every lab that we've covered. Whenever we compare the performance of two separate models, we are comparing the difference from two distinct starting points in the hypothesis space.\n",
    "\n",
    "A way to demonstrate this will be the basis of the first part of our lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.lda import LDA\n",
    "from sklearn.qda import QDA\n",
    "\n",
    "from bokeh.plotting import figure,gridplot,show,output_notebook\n",
    "from bokeh.models import Range1d\n",
    "output_notebook()\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Investigating Decision Boundaries\n",
    "Visually understanding how some classifiers make decisions; adapted from an sklearn page, which will be shared after lab. \n",
    "\n",
    "The goal here is to investigate the code and describe in layman's terms what is happening in the specific chunk. If there is a variable being referenced outside of your chunk, or your in a loop, refer to what's happening in one iteration of the loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# ====================================================================== #\n",
    "# Part 1\n",
    "\n",
    "names = [\"Nearest Neighbors\", \"Linear SVM\", \"RBF SVM\", \"Decision Tree\",\n",
    "         \"Random Forest\", \"AdaBoost\", \"Naive Bayes\", \"LDA\", \"QDA\"]\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(kernel=\"linear\", C=0.025),\n",
    "    SVC(gamma=2, C=1),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB(),\n",
    "    LDA(),\n",
    "    QDA()]\n",
    "\n",
    "X, y = make_classification(n_features=2, n_redundant=0, n_informative=2,\n",
    "                           random_state=1, n_clusters_per_class=1)\n",
    "rng = np.random.RandomState(2)\n",
    "X += 2 * rng.uniform(size=X.shape)\n",
    "linearly_separable = (X, y)\n",
    "\n",
    "datasets = [make_moons(noise=0.3, random_state=0),\n",
    "            make_circles(noise=0.2, factor=0.5, random_state=1),\n",
    "            linearly_separable\n",
    "            ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe here what is going on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "full_grid = []\n",
    "for data in datasets:\n",
    "# ====================================================================== #\n",
    "# Part 2\n",
    "\n",
    "    h = .02  # step size in the meshgrid\n",
    "    \n",
    "    X, y = data\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.4)\n",
    "\n",
    "    x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "    y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "\n",
    "    raw = figure(title=\"Raw Data\", tools='',\n",
    "                x_range=(xx.min(), xx.max()), \n",
    "                y_range=(yy.min(), yy.max()),\n",
    "                width=180, plot_height=220,\n",
    "                min_border=1,\n",
    "                title_text_font_size='10pt' )\n",
    "\n",
    "    color_dict = {0:'blue',1:'red'}\n",
    "\n",
    "    train_colors = [color_dict[label] for label in y_train]\n",
    "    raw.circle(X_train[:, 0], X_train[:, 1], \n",
    "               color=train_colors)\n",
    "\n",
    "    test_colors = [color_dict[label] for label in y_test]\n",
    "    raw.circle(X_test[:, 0], X_test[:, 1], \n",
    "               color=test_colors, alpha=0.6)\n",
    "\n",
    "\n",
    "    \n",
    "# ====================================================================== #\n",
    "# Part 3\n",
    "\n",
    "    row=[raw]\n",
    "    for name, clf in zip(names, classifiers):\n",
    "        clf.fit(X_train, y_train)\n",
    "        score = clf.score(X_test, y_test)\n",
    "\n",
    "        if hasattr(clf, \"decision_function\"):\n",
    "            Z = clf.decision_function(np.c_[xx.ravel(), yy.ravel()])\n",
    "        else:\n",
    "            Z = clf.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]\n",
    "\n",
    "        \n",
    "        Z = Z.reshape(xx.shape)\n",
    "        Z = Z/Z.max()\n",
    "        control_row = np.ones(Z.shape[1])+0.001\n",
    "        #NOTE: control row adds a max value outside of the grid to correct colors. \n",
    "        # Don't worry about explaining control_row\n",
    "        Z = np.vstack((Z,control_row))\n",
    "\n",
    "\n",
    "        p1 = figure(title=name, tools='',\n",
    "                    x_range=(xx.min(), xx.max()), \n",
    "                    y_range=(yy.min(), yy.max()),\n",
    "                    width=180, plot_height=220,\n",
    "                    min_border=1,\n",
    "                    title_text_font_size='10pt')\n",
    "\n",
    "\n",
    "        p1.image(image=[Z], x=[xx.min()], y=[yy.min()], dw=[xx.max()-xx.min()], dh=[yy.max()-yy.min()],\n",
    "                palette='RdYlBu11')\n",
    "\n",
    "        p1.circle(X_train[:, 0], X_train[:, 1], \n",
    "                  color=train_colors,\n",
    "                  line_color='black',\n",
    "                  size=3)\n",
    "        p1.circle(X_test[:, 0], X_test[:, 1], \n",
    "                  color=test_colors, \n",
    "                  alpha=0.6,\n",
    "                  line_color='black',\n",
    "                  size=3)\n",
    "\n",
    "        p1.text(x=[xx.max()-1.5],y=[yy.min()],\n",
    "                text=[str(score)],\n",
    "                text_font_size='15pt',\n",
    "                text_font_style='bold')\n",
    "        \n",
    "        row.append(p1)\n",
    "    \n",
    "    grid = np.array(row).reshape(2,len(row)/2)\n",
    "    full_grid.append(grid)\n",
    "    \n",
    "final_grid = np.vstack(full_grid)\n",
    "show(gridplot(final_grid.tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Random Forests\n",
    "Random forests are a type of ensemble method (which we hinted at above) that build out groups of decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import ShuffleSplit\n",
    "\n",
    "titanic = pd.read_csv('titanic-train.csv')\n",
    "titanic.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's preprocess our data. Age needs to be imputed or dropped, Sex needs to be converted to a boolean data type, and to use our categorical feature `Embarked` we must use `pd.get_dummies` on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "average_age = titanic['Age'].mean()\n",
    "titanic['Age'] = titanic['Age'].fillna(average_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "titanic['is_female'] = titanic.Sex=='female'\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "embarked_categories = pd.get_dummies(titanic.Embarked,prefix='Embarked')\n",
    "titanic[embarked_categories.columns] = embarked_categories\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_columns = 'Age,Parch,Pclass,Fare,Embarked_C,Embarked_Q,Embarked_S'.split(',')\n",
    "for train,test in ShuffleSplit(len(titanic),test_size=.2,n_iter = 1):\n",
    "\n",
    "    X_train = titanic[feature_columns].iloc[train]\n",
    "    y_train = titanic['Survived'].iloc[train]\n",
    "    X_test = titanic[feature_columns].iloc[test]\n",
    "    y_test = titanic['Survived'].iloc[test]\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We already imported the RandomForest above, but here it is for reference:\n",
    "# from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "\n",
    "rfc = RandomForestClassifier(max_depth=5, n_estimators=100, max_features=3)\n",
    "rfc.fit(X_train,y_train)\n",
    "rfc.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an interesting general score but let's be more thorough and get a cross evaluation score, and see how it grows with the size of our forest (`n_estimators`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "features = titanic[feature_columns]\n",
    "target = titanic['Survived']\n",
    "\n",
    "forest_size = range(2,100,2)\n",
    "y = []\n",
    "for i in forest_size:\n",
    "    rfc = RandomForestClassifier(max_depth=5, n_estimators=i, max_features=4)\n",
    "    accuracy = cross_val_score(rfc, features, target, cv=5).mean()\n",
    "    \n",
    "    y.append(accuracy)\n",
    "p1 = figure(title='Random Forest Classifier performance',tools='')\n",
    "p1.line(x=forest_size,y=y, color='green')\n",
    "\n",
    "\n",
    "show(p1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does the classifier change as we allow for more complexity?  (i.e. deeper trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tree_depth = range(1,50)\n",
    "y = []\n",
    "for i in tree_depth:\n",
    "    rfc = RandomForestClassifier(max_depth=i, n_estimators=20, max_features=4)\n",
    "    accuracy = cross_val_score(rfc, features, target, cv=5).mean()\n",
    "    \n",
    "    y.append(accuracy)\n",
    "p1 = figure(title='Random Forest Classifier performance',x_axis_label='Max Tree Depth',tools='')\n",
    "p1.line(x=tree_depth,y=y, color='green')\n",
    "\n",
    "\n",
    "show(p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Exercise: Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble.partial_dependence import plot_partial_dependence\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>account_length</th>\n",
       "      <th>area_code</th>\n",
       "      <th>intl_plan</th>\n",
       "      <th>vmail_plan</th>\n",
       "      <th>vmail_message</th>\n",
       "      <th>day_mins</th>\n",
       "      <th>day_calls</th>\n",
       "      <th>day_charge</th>\n",
       "      <th>eve_mins</th>\n",
       "      <th>eve_calls</th>\n",
       "      <th>eve_charge</th>\n",
       "      <th>night_mins</th>\n",
       "      <th>night_calls</th>\n",
       "      <th>night_charge</th>\n",
       "      <th>intl_mins</th>\n",
       "      <th>intl_calls</th>\n",
       "      <th>intl_charge</th>\n",
       "      <th>custserv_calls</th>\n",
       "      <th>churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KS</td>\n",
       "      <td>128</td>\n",
       "      <td>415</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>25</td>\n",
       "      <td>265.1</td>\n",
       "      <td>110</td>\n",
       "      <td>45.07</td>\n",
       "      <td>197.4</td>\n",
       "      <td>99</td>\n",
       "      <td>16.78</td>\n",
       "      <td>244.7</td>\n",
       "      <td>91</td>\n",
       "      <td>11.01</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.70</td>\n",
       "      <td>1</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OH</td>\n",
       "      <td>107</td>\n",
       "      <td>415</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>26</td>\n",
       "      <td>161.6</td>\n",
       "      <td>123</td>\n",
       "      <td>27.47</td>\n",
       "      <td>195.5</td>\n",
       "      <td>103</td>\n",
       "      <td>16.62</td>\n",
       "      <td>254.4</td>\n",
       "      <td>103</td>\n",
       "      <td>11.45</td>\n",
       "      <td>13.7</td>\n",
       "      <td>3</td>\n",
       "      <td>3.70</td>\n",
       "      <td>1</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NJ</td>\n",
       "      <td>137</td>\n",
       "      <td>415</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>243.4</td>\n",
       "      <td>114</td>\n",
       "      <td>41.38</td>\n",
       "      <td>121.2</td>\n",
       "      <td>110</td>\n",
       "      <td>10.30</td>\n",
       "      <td>162.6</td>\n",
       "      <td>104</td>\n",
       "      <td>7.32</td>\n",
       "      <td>12.2</td>\n",
       "      <td>5</td>\n",
       "      <td>3.29</td>\n",
       "      <td>0</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OH</td>\n",
       "      <td>84</td>\n",
       "      <td>408</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>299.4</td>\n",
       "      <td>71</td>\n",
       "      <td>50.90</td>\n",
       "      <td>61.9</td>\n",
       "      <td>88</td>\n",
       "      <td>5.26</td>\n",
       "      <td>196.9</td>\n",
       "      <td>89</td>\n",
       "      <td>8.86</td>\n",
       "      <td>6.6</td>\n",
       "      <td>7</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OK</td>\n",
       "      <td>75</td>\n",
       "      <td>415</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>166.7</td>\n",
       "      <td>113</td>\n",
       "      <td>28.34</td>\n",
       "      <td>148.3</td>\n",
       "      <td>122</td>\n",
       "      <td>12.61</td>\n",
       "      <td>186.9</td>\n",
       "      <td>121</td>\n",
       "      <td>8.41</td>\n",
       "      <td>10.1</td>\n",
       "      <td>3</td>\n",
       "      <td>2.73</td>\n",
       "      <td>3</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  state  account_length  area_code intl_plan vmail_plan  vmail_message  \\\n",
       "0    KS             128        415        no        yes             25   \n",
       "1    OH             107        415        no        yes             26   \n",
       "2    NJ             137        415        no         no              0   \n",
       "3    OH              84        408       yes         no              0   \n",
       "4    OK              75        415       yes         no              0   \n",
       "\n",
       "   day_mins  day_calls  day_charge  eve_mins  eve_calls  eve_charge  \\\n",
       "0     265.1        110       45.07     197.4         99       16.78   \n",
       "1     161.6        123       27.47     195.5        103       16.62   \n",
       "2     243.4        114       41.38     121.2        110       10.30   \n",
       "3     299.4         71       50.90      61.9         88        5.26   \n",
       "4     166.7        113       28.34     148.3        122       12.61   \n",
       "\n",
       "   night_mins  night_calls  night_charge  intl_mins  intl_calls  intl_charge  \\\n",
       "0       244.7           91         11.01       10.0           3         2.70   \n",
       "1       254.4          103         11.45       13.7           3         3.70   \n",
       "2       162.6          104          7.32       12.2           5         3.29   \n",
       "3       196.9           89          8.86        6.6           7         1.78   \n",
       "4       186.9          121          8.41       10.1           3         2.73   \n",
       "\n",
       "   custserv_calls   churn  \n",
       "0               1  False.  \n",
       "1               1  False.  \n",
       "2               0  False.  \n",
       "3               2  False.  \n",
       "4               3  False.  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/cell_phone_churn.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Some Prepreocessing\n",
    "state_encoder = LabelEncoder()  \n",
    "df.state = state_encoder.fit_transform(df.state)\n",
    "\n",
    "\n",
    "binary_columns = ['intl_plan', 'vmail_plan', 'churn']  \n",
    "for col in binary_columns:  \n",
    "    df[col] = df[col].map({\n",
    "            'no': 0\n",
    "        ,   'False.': 0\n",
    "        ,   'yes': 1\n",
    "        ,   'True.': 1\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps:\n",
    "----\n",
    "1. Explore the data and plot histograms of several columns. Hypothesize whether a relationship exists. \n",
    "2. Evaluate and compare the `precision and recall` of \n",
    "    - `GradientBoostingClassifier` \n",
    "    - `RandomForestClassifier`\n",
    "    - `DecisionTreeClassifier`\n",
    "    - `Logistic Regression`\n",
    "        - hint!: use the `precision_recall_fscore_support` built into sklearn \n",
    "3. Tune the models using a grid-search of several parameters \n",
    "    - Determine which score (accuracy? F1 score? ...) you will use for your grid search. Explain why to your partner\n",
    "    - Hint: for `DecisionTreeClassifier` and `RandomForestClassifier`, \n",
    "        look at the docs to see which hyperparameters need tuning.  \n",
    "4. Plot feature importance for one of your models (using the `.feature_importances_` property)\n",
    "    - Hint: load `feature_importances_` into a `pandas.Series` and use `.plot(kind='barh')` \n",
    "5. Plot a learning curve for the same model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Your Code here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
